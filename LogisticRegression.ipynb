{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pVNe9GbYvrp"
      },
      "source": [
        "**Creating another model for the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 100 folds for each of 5 candidates, totalling 500 fits\n",
            "Best parameters found:  {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Accuracy: 0.83\n",
            "Precision: 0.81\n",
            "Recall: 0.86\n",
            "F1 Score: 0.83\n",
            "ROC-AUC: 0.89\n",
            "Optimized prediction results have been saved to 5014.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    df = df[~((df[column] < (Q1 - 1.5 * IQR)) | (df[column] > (Q3 + 1.5 * IQR)))]\n",
        "    return df\n",
        "\n",
        "def calculate_accuracy(TP, TN, FP, FN):\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "    return accuracy\n",
        "\n",
        "def calculate_precision(TP, FP):\n",
        "    precision = TP / (TP + FP)\n",
        "    return precision\n",
        "\n",
        "def calculate_recall(TP, FN):\n",
        "    recall = TP / (TP + FN)\n",
        "    return recall\n",
        "\n",
        "def calculate_f1(precision, recall):\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1_score\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
        "    TP = sum((y_true == 1) & (y_pred == 1))\n",
        "    TN = sum((y_true == 0) & (y_pred == 0))\n",
        "    FP = sum((y_true == 0) & (y_pred == 1))\n",
        "    FN = sum((y_true == 1) & (y_pred == 0))\n",
        "    \n",
        "    accuracy = calculate_accuracy(TP, TN, FP, FN)\n",
        "    precision = calculate_precision(TP, FP)\n",
        "    recall = calculate_recall(TP, FN)\n",
        "    f1 = calculate_f1(precision, recall)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    \n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "    print(f'Precision: {precision:.2f}')\n",
        "    print(f'Recall: {recall:.2f}')\n",
        "    print(f'F1 Score: {f1:.2f}')\n",
        "    print(f'ROC-AUC: {roc_auc:.2f}')\n",
        "    \n",
        "    return accuracy, precision, recall, f1, roc_auc\n",
        "\n",
        "# Load the dataset\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Remove outliers for numeric features\n",
        "numeric_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "for feature in numeric_features:\n",
        "    train_df = remove_outliers_iqr(train_df, feature)\n",
        "\n",
        "# Splitting dataset into features and target variable\n",
        "X = train_df.drop(columns=['y'])\n",
        "y = train_df['y'].map({'yes': 1, 'no': 0})  # Convert 'yes'/'no' to 1/0 for training\n",
        "\n",
        "# Define preprocessing for numeric and categorical features\n",
        "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "\n",
        "# Build preprocessing pipelines\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine preprocessors\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Add feature engineering steps like Interaction Terms and Principal Component Analysis\n",
        "feature_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('pca', PCA(n_components=20))\n",
        "])\n",
        "\n",
        "# Encode the datasets\n",
        "X_encoded = feature_pipeline.fit_transform(X)\n",
        "X_test_encoded = feature_pipeline.transform(test_df)\n",
        "\n",
        "# Handling Imbalanced Data with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X_encoded, y)\n",
        "\n",
        "# Train-Test Split after resampling\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "logistic_model = LogisticRegression(random_state=42, max_iter=500)\n",
        "\n",
        "# Define hyperparameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'penalty': ['l1'], # Regularization terms: Lasso, Ridge, ElasticNet, or none. #'l1', 'l2', , 'none'\n",
        "    'C': [0.1], # Inverse regularization strength.\n",
        "    'solver': ['saga'], # Optimization algorithms.\n",
        "    'max_iter': [100, 200, 300, 500, 1000], # Maximum number of iterations.\n",
        "    # 'l1_ratio': [0.0, 0.2, 0.5, 0.8, 1.0] # ElasticNet mixing ratio (for 'elasticnet' penalty).\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(logistic_model, param_grid, cv=100, scoring='f1', verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Get the best model from grid search\n",
        "best_logistic_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on validation data\n",
        "y_pred = best_logistic_model.predict(X_valid)\n",
        "y_pred_proba = best_logistic_model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Evaluate the model using custom metric functions\n",
        "_, _, _, _, _ = calculate_metrics(y_valid, y_pred, y_pred_proba)\n",
        "\n",
        "# Make predictions on the test data\n",
        "test_pred_proba = best_logistic_model.predict_proba(X_test_encoded)[:, 1]\n",
        "test_df['y'] = np.where(test_pred_proba > 0.5, 'yes', 'no')\n",
        "\n",
        "# Save the updated test dataframe to a new CSV file\n",
        "test_df.to_csv('5014.csv', index=False)\n",
        "\n",
        "print(\"Optimized prediction results have been saved to 5014.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
